# Java基础

## SPI

service provider interface

- 首先有一个公共接口，
- 第三方实现这个接口
- 在META/INFO/services 目录下创建一个以该接口全限定名为名字的文件，内容为实现类的全限定名
- JVM使用ServiceLoader加载 servlceLoader是Java内置的服务发现工具，用于加载指定接口的实现类，并返回实现类的迭代器
- serviceLoader会分别加载META/INFO/serives中的全限定名，使用线程上下文中的类加载器(一般是应用程序类加载器)

## lambda表达式

lambda是java8的新特性，用于简化函数式接口的开发，使用参数列表+方法体的方式创建匿名函数，作为方法参数传递

函数式接口 - @FunctioinalInterface，只包含一个抽象方法的接口，常用来指定一个逻辑，作为某些方法执行的依据

lambda的出现使得 使用简单的语句代替匿名类的实现，代码清晰，思路清晰



- 配合stream使用
- 方法参数，比如排序方式比如Runnable接口



- 对于局部变量 必须为final的或者非final但是定义完之后没有修改语句的变量
- 对于成员变量，可以随意访问，并且没有约束

lambda在方法中是要去捕获变量的值

要求局部变量不会变，防止引用失效

对于成员变量，不会直接捕获变量本身，而是会去捕获对象引用，所以变量可变

## 方法重载

方法重载要求方法签名不同，方法签名包括方法名和参数列表

方法名肯定要一样，所以只能参数列表不一样

所以仅仅返回值，访问修饰符，异常不同不算是重载

## 方法重写

- 方法签名完全相同 - 方法名 + 参数列表
- 返回值兼容 - 基本数据类型完全一致，引用数据类型为父类的子类或相同
- 访问修饰符不能更严格 - private - default - protected - public
- 异常范围不能更大，子类抛出异常只能是父类抛出的子类或相同

## 访问修饰符

控制类，方法，字段的访问范围

|  修饰符   | 本类内部 | 同一个包 | 不同包子类 | 不同包非子类 |
| :-------: | :------: | :------: | :--------: | :----------: |
|  private  |    1     |    0     |     0      |      0       |
|  default  |    1     |    1     |     0      |      0       |
| protected |    1     |    1     |     1      |      0       |
|  public   |    1     |    1     |     1      |      1       |

## 异常处理

方法会在方法栈帧的帧数据中存储异常表(可能有很多个异常记录)

异常表记录 - **1.异常检查相对于try的字节码偏移量范围 2.catch的起始位置 3.捕获的异常类型**

如果一处发生异常 记录异常语句的字节码地址(当前程序计数器的值) 遍历异常表的所有条目

观察是否有范围和异常类型完全匹配的条目 **有根据catch位置继续执行** 否则方法终止，**弹出栈帧，回到调用方的栈帧**，重复异常表检查

**直到找到符合条件的异常记录 或者 到达栈底，也就是线程入口**

finally - 编译器通过将finally的内容复制到可能的所有退出路径 - **1.try正常结束，2.catch捕获异常后，3.catch未能成功捕捉 向外抛出前**

**HotSpot虚拟机会用jit优化多个try catch 内联优化**

## Stream流

**声明式编程**  stream本身不存储数据作为**数据源的操作视图**

**流水线结构**

每个中间操作和结束操作都被封装成一个**stage对象**，形成双向链表的结构

中间操作不会立即执行，**记录操作逻辑**，直到终止操作**触发链式操作**

多个中间方法最后终结方法，**形成stage链表，形成流水线**，目标数据元素**依次通过流水线**，而不是对所有元素都执行完某一个中间操作再往下执行

(依次通过的意义 - 更好得使用并行流 减少循环次数，本来每个stage处for一次 现在对于流水线for一次)

集合 数组 零散数据都可以变成stream流

方法调用分为**中间方法和终结方法**

**中间** - 过滤，去重，跳过，map值转换

**终结** - 遍历，统计计数，转换成数组和集合

数组的stream流收集成集合 要使用.boxed()装箱操作变成**包装类**

**并行流的原理** - 将数据源利用**可分割迭代器**将数据源分为多个字任务分别执行最后合并

stream需要创建许多中间对象，有很多抽象概念，还有很多装箱拆箱问题，数据小性能比for差，使用并行流                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        

## Java相对c++慢的原因

- java 解释+编译 c++ 编译
- 垃圾回收 c++手动高效
- java跨平台牺牲 c++可以根据不同系统采用特定优化
- c++静态优化效率高于java jit运行时优化
- c++ 提供对操作系统和硬件的直接访问，java依赖jvm和标准裤，有时候还要调用native方法





## 数据库缓存一致性策略

- 旁路缓存cache-aside 改数据库删缓存 感觉还是不行就延迟双删
- 直写write through 跟新缓存跟新数据库
- 异步回写 write behind跟新缓存，异步写入数据库
- 跟新数据库 使用MQ或者canel
- 分布式锁 同时跟新缓存和数据库



旁路缓存最常用

两个write适合写多的操作

不追求数据一致性 缓解业务压力

强一致性

## 序列化和常见框架

- 对象实现Serializable标记接口，用于将对象转换成字节流的过程，用于网络传输或者持久化存储

- transient关键字标记的对象不会被序列化

- serialVersionUID版本id，序列化后修改类结构导致版本id变化，会造成序列化失败

(serialVersionUID最好手动维护`private static final long serialVersionUID = 1L;`)

(若是java虚拟机自动维护的，序列化之后，如果对程序进行比如更改注释，变更了方法参数的位置之类的不会影响类本身的操作，会导致反序列化失败，InvalidClassException，如果是手动维护的，不去更改，就不会有问题)

- Externalizable继承自Serializable，需要手动实现序列化和反序列化过程

readResolve 可以手动重写这个方法，反序列化时候会调用这个实现，用于实现单例对象

- 原生序列化 - Serializable readObject方法反序列化一个字符流成对象
- FastJson
- jackson - 序列化反序列化成json字符串
- Gson 类似jackson 效率略低
- Protocol Buffers .proto文件
- Hessian 二进制序列化框架



## 自定义注解

- @interface创建
- 元注解表示 保留策略(保留在编译阶段，编译结束后就没了 还有类似的保留在运行阶段)
- 注解目标（class ? method?）
- 使用
- 自定义反射或者动态代理aop实现对使用注解的目标进行逻辑处理

## 限流算法

- **漏桶算法原理**：请求就像水一样流入漏桶，漏桶以固定的速率处理请求。如果请求的流入速度超过了漏桶的处理速度，多余的请求会被丢弃。
- **令牌桶算法原理**：系统以固定的速率生成令牌放入桶中，请求需要从桶中获取令牌才能被处理。只要桶中有令牌，请求就能立即得到处理





## 项目(数据)初始化

- 在一些实现业务注入的bean中，使用@PostConstruct，其中书写数据初始化(缓存预热的工作也可以)
- 实现ApplicationRunner，springBoot容器启动完成后的Runner自定义初始化逻辑
- 使用@Value + ${name}的方式读取配置文件中的内容
- @Scheduled 周期去跟新缓存中的内容

## 面向对象之开闭原则

软件实体（类、模块、函数等）应该对**扩展开放**，对**修改关闭**

降低代码修改带来的风险，提高系统可拓展性，增强代码复用性



- 使用接口，抽象类
- 使用工厂类
- 使用策略模式

## 双token登陆

1. 用户登陆，验证完成身份信息后，服务端生成两个token，Access Token(短有效期) 和 Refresh Token(长有效期)，并将两个token返回给客户端
2. 客户端可以选择将Access Token放在内存或者localStorage或者sessionStorage(不放在cookie，防止CSRF)，但是Refresh Token一定要放在Http-only Cookie中，用于防治XSS问题，服务端将Refresh Token放在Redis中，用于验证Refresh Token的合法性
3. 用户每次登陆将Access Token放在请求头的Authorization中，服务端验证是否过期，如果过期，返回报错，前端尝试调用刷新token接口，里面包含Refresh Token，如果服务端验证其合法(没过期，和数据库中记录匹配)，则重新生成一个Access Token返回给前端，前端跟新
4. 当用户退出，将Access Token 和 Refresh Token全都删除

- 首先，服务端可以控制退出 - 删除数据库中的Refresh Token
- 解决CSRF - access Token通过请求头发送，无法同源自动传输
- 解决XSS - refresh Token存储在http-only cookie，无法通过js脚本直接获取



Refresh Token 一定要在 **HttpOnly + Secure Cookie**

http-only cookie可以限制禁止js访问cookie中的内容，localStorage或者sessionStorage虽然容量大，操作容易会直接暴露信息给js

将Cookie的secure属性设置为true，要求cookie只能通过https加密连接传输，防止中间人攻击(HTTP明文传输截获Cookie)

推荐将Refresh Token绑定用户ip，进行一些额外判断





XSS - 跨站脚本攻击

攻击者通过在Web页面中注入恶意的JavaScript代码通过document.cookie窃取存储在浏览器中的敏感信息 - token cookies，模拟用户的合法信息进行请求攻击

- **HTTP-only Cookies**：将敏感的Cookie标记为`HttpOnly`，使得它们无法通过JavaScript访问。



CSRF - 跨站请求伪造

欺骗已认证的用户在不知情的情况下向目标网站发起恶意请求，请求会自动携带浏览器的cookie

**SameSite Cookie**：设置 Cookie 的 `SameSite` 属性为 `Strict` 或 `Lax`，限制跨站请求时自动发送Cookie，从而避免携带认证信息。

**Referer头检查**：检查请求的 **Referer** 头，确保请求来源是可信的。

**CSRF Token** 每次客户端发送请求，服务器生成一个独一无二的CSRF Token并将其嵌入到页面中，封装在请求头或者请求体中发送，服务器持久化这个csrf token，并每次对请求验证csrf token的合法性，判断是否有效



关于cookie传递的同源策略

限制一个源的文档或者脚本和另一个源的资源进行交互的策略

两个页面的协议，域名，端口号都一样的时候认为他们是同源的

当在一个页面中发送一个同源的请求，会自动将与这个源相关的cookie包含在请求中发送给浏览器

如果是跨域请求，需要通过额外配置，比如CORS来允许跨源访问



token放在请求头而不是cookie的原因

- 防止CSRF跨站请求伪造，cookie会自动同源请求发送，请求头不会像 Cookie 那样自动发送，需要主动设置
- cookie没有设置http-only的话，可以被js访问，请求头中的 Token 不会被页面上的 JavaScript 轻易访问
- cookie需要配置跨域问题，前端只需要在每次请求时将 Token 手动添加到请求头中
- 微服务架构或多个系统集成的场景中，不同系统可能有不同的身份验证需求，Token 放在请求头中可以更灵活地在不同系统之间传递和验证，而不需要依赖于特定的 Cookie 机制
- 每个域名下的cookie大小有限制，请求头的大小限制相对较大





如果只使用一个token，数据库中建立其过期时间，token存放在http-only中

- token jwt实现，自己维护一个过期时间，和数据库中维护时间的一致性关系很难保证
- 若是发现token泄漏，后端无法主动吊销token，双token的情况下，可以删除数据库中的Refrsh Token
- 还是存在CSRF攻击，要配置sameSite属性或者开启**额外CSRF防护机制**
- 每次请求都要查询redis

## JWT

**组成**：

- Header 头部 - 令牌类型和签名算法
- Payload 有效荷载 - 用户数据，过期时间
- Signature - 将Header和Payload的Base64Url编码拼接，通过指定算法和密钥进行签名(先对header和payload进行编码后拼接密钥，使用签名算法进行加密)

通过密钥和签名(jwt本身)创建出JWT解析器，验证签名，并判断是否过期

**优点**：

- 无状态 - 通过jwt直接验证是否过期，服务端无需额外存储认真信息
- 支持跨域，单点登录和跨服务认证
- 在token内部封装信息，减少数据库的查询



**潜在问题**：

- 可以伪造签名
- Payload 仅 Base64 编码（非加密，可逆），应避免存储敏感数据，建议使用 HTTPS
- 体积大，一般存储在localStroage，存在XSS攻击
- token无法主动失效，有效期内即使账号异常，也无法直接失效 Token，需结合黑名单机制（可能牺牲无状态性）

## ❄️算法

**符号位 + 时间戳 + 数据中心ID + 机器ID + 序列号 + 保留位**

- 符号位 - 1bit - 0正1负，一般用0表示正
- 时间戳 - 41bit - 毫秒级别，一个毫秒一个
- 数据中心id - 机器id - 各5bit - 所以一共可以表示1024个机器
- 序列号 - 12bit - 每毫秒内递增，最大4095，达到最大值，会等待下一毫秒
- 保留位 - 通常用不到为0 - 可以用于拓展



常见的❄️算法实现器 - Twitter Snowflake - Leaf Snowflake(美团)

```java
// 机器 1，数据中心 1，机器 ID 1
SnowflakeIdGenerator idGenerator1 = new SnowflakeIdGenerator(1, 1);
```

使用的时候指定数据中心id和机器id



**为什么机器数超过1024就不行**

数据中心id+机器id 一共10bit，可以表示1024个机器

如果超过可以尝试减少时间戳位数，或者使用最后一个保留位



**时钟回拨**指的是系统时钟突然倒退的情况，可能会导致生成的 ID 重复。因为在雪花算法中，生成 ID 的时间戳是基于当前的系统时间，而如果系统时间回拨，可能会出现生成的 ID 小于先前生成的 ID，从而导致重复。

- 检测并等待 - 生成id时候检测时钟是否回拨，（当前时间戳比上次小）阻塞等待一定时间，知道时间恢复正常
- 设定最大等待时间，超过这个时间没有恢复正常，就比如报错
- 使用分布式时钟同步工具，NTP，或者自己写一个工具类（Async-Tool中的实现）

## 基本数据类型和其包装类的存在

- 作为对象封装后，可以编写许多快捷方法，比如Integer的parseInt，将String快速转为int
- 满足范型使用需求
- 支持序列化和反序列化
- 便于空值null的处理，基本数据类型没有空值，只有默认值





## 登录模块怎么防止用户重复登录

用户在一处登录，另一处如果有登录，一定会下限

- 基于token，用户的登录凭证加入缓存保存，每次登录生成新token，并使老token失效
- 如果使用分布式session保存用户数据，每次登录删除老session，创建新的session
- 在redis中绑定用户id和身份信息，每次登录请求覆盖redis值的内容，并且可以绑定ip等信息
- 为jwt维护一个黑名单，新登录后，把旧jwt加入黑名单
- 综合ip等信息制造认证token，异地等登录进行多维度信息判断校验
- 异常登录出发二次验证

## 秒杀系统如何防止用户重复下单

- 前端在一次按钮点击玩后立即禁用，直到请求返回，关键操作之前增加验证码
- 前端秒杀成功直接跳转页面
- 如果全局只能一次，综合用户的ip，设备id等关键字，综合加密，加入缓存
- 为用户id+商品id在数据库层面建立唯一索引
- 每个用户下单前，尝试去获取以用户id为key的分布式锁
- 请求异步化，限制数量的同时，以用户的请求加入到消息队列为成功标志，利用消息队列完成幂等性
- 用户进入秒杀页面，后端分配一个购买令牌，用户秒杀请求中携带令牌，前端填充令牌后立马本地删除，防止二次添加

## 异步下单问题

**考虑异步下单原因**

- 提高响应速度，秒杀活动中，并发量大，快速响应用户请求
- 提高系统吞吐量，系统的并发量上升，同时可以处理更多请求
- 业务结偶，可拓展性提高

**可能造成的损失**

- 订单延迟，订单位于MQ排队，用户无法马上看到请求的具体结果信息
- 数据不一致问题，加入MQ后认为下单成功，但是由于网络或者逻辑的问题其实这个订单是非法的，超出库存的，无法作出及时的反馈，影响用户体验
- 交易非实时，可能存在问题

**库存不足但已返回订单号的处理方法**

- 使用websocket或者短信什么的方式去通知用户
- 持续监控库存等信息，将用户加入到优先级队列，以高次序高优先级去再次获取库存

## Jar/War包问题

**Jar ** - 

- Java的归档文件(多个文件目录集合打包成单个文件存储 便于数据整合，结构维护) 
- 将有关Java应用的类文件，资源文件，元数据文件打包成一个文件 
- 可以直接运行(有主类 Main Class)或者作为其他其他程序的依赖

**Jar 包分类** - 

- Fat Jar - 内嵌所有依赖包，可以直接运行
- Thin Jar - 项目代码和依赖Jar包清单，需要额外配置

SpringBoot的jar是Fat Jar 内嵌Web服务器并打包所有依赖，可以直接运行

对于Fat  Jar 内嵌jar包，Java原生类加载器无法加载内掐包，SpringBoot创建专属内嵌包类加载器

**实现**

- Java类路径下的 公共包 可能和 Far 里边的 内嵌包 存在 版本上的不同， 需要优先使用 自己的版本，而不是公共的版本。
- 不同的 Spring Boot 需要支持不同模块或插件加载相同类的不同版本 , 优先加载 内嵌包， 可独立管理依赖，实现版本隔离， 以及实现 **模块化隔离**



**War** - 

- Java Web的归档文件，包含所有Web组件(web配置，类文件，html js资源)
- 需要部署到Servlet容器启动，如Tomcat Jetty

## 栈队列的相互实现

用两个栈实现队列 - 

两个栈

一个栈存数据，当发送取队列头元素，或者出队操作

把栈中元素按栈的顺序取出放到第二个栈，此时为当前元素的逆序，取元素和出队直接操作

这个栈中的元素被消耗完了，就再从第一个栈中逆序把元素加载进来





两个队列实现栈

每次元素入队列A，当要出栈，把n-1个元素加入队列B，最后一个元素抛弃

若取元素，n-1个元素入队后，返回最后一个元素值，再将其入队

# **场景问题**

## 并发读取消费大量数据

我有一个百万级别数据行的excel文件，一个数据行要消费1s左右，怎么实现快速消费

**主要思路** - 使用MQ + java多线程

**整体流程** - Excel文件 - 分片读取 - 发送到消息队列 - 多个消费者消费 - (结果汇总？)

- 使用Apache POI的SAX模式(事件模型)读取Excel ，避免把整个文件加载到内存中(SAX解析器每次读取一行，积累到一个阈值，形成一个chunk，批量发送到MQ中，只有当前批次的chunk会保存在内存中)
- 一台实例就专门负责把chunk上传到MQ中去
- 消费者在消费的时候，以chunk为单位，首先从MQ中获取一整个批次的数据，然后利用多线程去并行处理



**一些实现的细节**

- 控制好chunk的大小，太大网络传输慢，太小序列化反序列化的占比大，效率低
- (数据完整性要求高)投递和消费信息都要做好**幂等性**的判断(MQ本身实现，或者手动维护id)
- 对于rabbitMQ，使用队列消费者群消费(设置好预取值)，对于kafka，建立好分区副本机制
- MQ维护好**内存淘汰策**略，rabbitMQ直接淘汰最老数据(kafka调整定期清理事件，或者开启日志压缩)
- 监控**MQ的压力**，防止出现消息堆积，根据积压情况去调整消费者的数量或者逻辑
- 首先**快速消费**，对于消费失败的消息单独加入一个集合，后续统一再处理(rabbitMQ可以直接使用死信队列)
- 在每个java进程内部维护**线程池**，多开消费者，不同消费者争抢这里面的线程去做消费任务，避免线程的频繁创建销毁
- 如果对于数据的**完整性要求没有那么大**，可以适当降低MQ的一致性维护，以提高性能，比如说offset自动提交，比如说不开启消息确认，或者自动消息确认

## Mysql1000w，Redis20G缓存设计

**分析**

- 数据存储在mysql，成本低，读取速度慢，存储在缓存获取效率高，但是内存大小有限
- 全量数据总量非常大，缓存的覆盖率低
- 流量抖动严重，要设计合理的方案保证缓存中存储的都是热点数据



**1 - 首先数据一定是冷热分离的**

全局的逻辑

数据库存储冷数据，热数据一定是维护在缓存中的，提高访问效率

**2 - 命中率治理**

Redis相对于Mysql容量太小，需要维护好合适的内存淘汰策略

默认的内存淘汰策略是 - 不淘汰key，拒绝写入并报错

为了提高缓存的高可用，在保证缓存数据为热点数据的前提下，不会被随意替换出去，所以不使用随机淘汰的策略

应该使用LRU(访问时间，适用于数据冷热分层明显，冷数据基本不会变热的场景，比如一些用户聊天内容，一般是不会常看之前记录)或者LFU(访问频次，数据访问频次差异大，并且是长期访问趋势的场景 - 秒杀场景，热点数据集中，并要排除其他冷数据干扰 / 电商页面)

**3 - 热点探测**

靠Redis的内存淘汰策略是被动的，需要主动识别热点，引入实时热点探测系统

可以使用京东的HotKey组件

<u>主要功能流程</u>

- 客户端拦截所有请求，统计热点 根据阈值标记热点key
- 定期把本地热点 Key上报HotKey服务端，服务端进行整合，找出全局热点Key，并定期推送给客户端
- Zookeeper(利用watch机制)作为协调中心，存储热点列表，定时跟新，让Redis根据列表调整缓存，延长热点Key过期时间，优先把热点Key分配给高性能节点



- 高命中率
- 防止缓存雪崩
- 优化资源精准分配

**4 - 多级缓存**

优先接入层Nginx字典返回数据，

如果没有在进入服务层从caffeine缓存中获取数据，

caffeine拿不到数据在去缓存层redis中获取数据，

redis拿不到数据在去兜底的mysql中获取数据，

获取到数据后，再把缓存上层的数据回填

内存小 -  大 数据 - 频繁 - 不频繁

**5 - 多维度预热**

每日业务低谷期，分析访问日志，预热top数据，不同于上述的实时预热，这个是定时预热，保证多维度的准确性



**其他**

- 业务隔离(不同业务用不同缓存实例)
- 缓存雪崩解决 热点Key解决
- 热点Key分片
- 每日运维，探测热点Key，删除淘汰缓存中的非热点Key
- 检测预警(击穿率过大 - 检测热点探测是否失败 ，内存使用率过高 - 准备扩容或者跟新内存淘汰策略 - 某个Key qps过高 - 分片)

# Spring全家桶

## mini-spring的启动流程(ApplicationContext)

- 从new一个ClassPathXmlApplicationContext开始(参数是配置文件地址)，进入内部refresh逻辑
- 根据传入的地址，创建一个DefaultListableBeanFactory对象，并通过BeanDefinitionReader加载BeanDefinition
- 应用BeanFactoryPostProcessor的实现类
- 提前getBeanOfType，把所有的BeanPostProcessor的实现类加入到AbstractBeanFactory的容器管理(方便bean使用，不用每次都去getBean)
- 注册感知ApplicationContext容器的BeanPostProcessor
- 初始化事务发布者(ApplicationEventMulticaster - 发布事物，判断一个监听器是否对某个事物感兴趣)
- 注册事物监听器(加入ApplicationEventMulticaster容器管理，方便其做感兴趣判断)
- 提前实例化单例bean
- 发布容器刷新完成的事件

## spring aop 实操步骤

**xml**

![image-20250301203421300](https://typora---------image.oss-cn-beijing.aliyuncs.com/image-20250301203421300.png)

1 - 定义一个Advice(就是一个普通的类，用于获取里面的方法)

2 - 在<aop:config> 内定一个切点表达式

3 - 维护一个切面 内部一个advice 一个 切点表达式 ---- 织入的过程



**annotation**

1 - 在类上加上切面注解

2 - 在一个方法上，配置切面(用于根据方法获取切面)

3 - 在具体的方法上使用@Before @After（内部直接写引用的切面，也可以用AspectJ重新写一个）

## SpringBoot自动装配的过程

- 启动类上@SpringBootApplication(@SpringBootConfiguration + @ComponentScan + @EnableAutoConfiguration)
- Spring Boot 加载 `META-INF/spring.factories` 中预定义了所有自动配置类(一些类的全限定名)
- 根据条件化注解，筛选真正需要的配置项(在获取目标bean的方法上(手动配置的自动配置逻辑)加上@ConditionalOnClass 类路径下存在指定类生效 @ConditionOnMissingBean容器中不存在指定Bean生效)
- 经过筛选后，符合条件的自动配置类会被加载并生效。自动配置类通常是带有 `@Configuration` 注解的类，它们会定义一些 Bean 的创建和配置逻辑，从而完成 Spring 应用的自动配置。
- 用户手动定义的bean会覆盖自动配置的bean

## SpringBoot的启动流程

- **入口**位于@SpringBootApplication的SpringApplication.**run**()处，开始初始化容器和环境
- run() 前的构造函数中  加载META-INF/spring.factories中的**配置**，并且初始化其中的全局事件监听器
- run()方法内部，启动一个**定时器**，用于统计启动耗时，检测性能
- 配置**HeadLess**模式，确保服务器环境下无图形界面时正常运行
- 发布**ApplicationStartingEvent**容器开始事件
- 准备环境，加载**application.properties/yml**中的配置，发布ApplicationEnvironmentPreparedEvent  应用环境准备事件
- 打印**Banner** - 在classpath下添加banner.txt 实现Banner接口并注册成Bean (控制台的那个横幅)
- **创建**应用上下文(分为Selvet的还有非Web的等)
- **准备**上下文 - 执行ApplicationContextInitializer的容器初始化方法初始化方法
- **刷新**上下文 - 校验环境变量 - 创建BeanFactory - 根据注解加载Bean - 应用BeanfactoryPostProcessor - 注册BeanPostProcessor - 初始化国际化资源 - 初始化spring的事件广播器 - 初始化事件监听器 - 实例化单例Bean - 发布容器初始化完成事件
- 执行**Runner**接口的实现类，实现容器启动后的自定义逻辑
- 发布**容器启动**事件
- 返回ApplicationContext引用 



## SpringTask 和 @Scheduled的关系

spring task 是spring实现定时循环任务的组件

内部维护一个**TaskScheduler**的接口(描述定时任务执行)

有默认(除非自己实现一个TaskScheduler)的管理定时任务的线程池 - ThreadPoolTaskScheduler(引用newScheduledThreadPool)

@Scheduled 封装好内部调用内部循环线程池的工作 暴露给外界

## springBoot特性总结

- 快速搭建项目(提供起步依赖strater，减少手动管理依赖的工作量)，(项目在线结构生成器，生成目录骨架)
- 自动配置+条件化注解(@ConditionalOnClass   @ConditionalOnMissingBean)
- 嵌入式服务 - tomcat服务器无需打包成war 直接打包成jar
- 完善的监控和安全组件
- 微服务支持
- 测试便利



## Resource Autowired

使用在字段还有setter方法上 实现bean的注入  @Resource不是spring的注解 但是支持使用

**@Autowired** 默认要求注入内容一定要存在(不然将required属性设置为false)

byType注入 如果有多个同类型对象则会发生注入报错 解决 - (使用@Qualifaier 指定注入的name)(对bean设置@Primary标记为优先注入)(使用一个list集合变量接收)

**@Resource**

可以根据name和type注入 byName是默认的方式 没有指定name和type直接自动使用byName

使用buType如果没有匹配或者有多个结果也会同样报错

## Spring事物传播级别

- **PROPAGATION_REQUIRED** - 若调用方方法存在事务，被调用方法会加入该事务；若调用方方法没有事务，被调用方法会创建一个新事务。
- **PROPAGATION_REQUIRES_NEW** - 不管调用方方法是否存在事务，被调用方法都会创建一个新的事务。若调用方方法存在事务，会将其挂起，等新事务执行完毕后，再恢复原来的事务。
- **PROPAGATION_SUPPORTS** - 如果调用方方法存在事务，被调用方法会加入该事务；若调用方方法没有事务，被调用方法会以非事务方式执行。
- **PROPAGATION_NOT_SUPPORTED** - 被调用方法会以非事务方式执行。若调用方方法存在事务，会将其挂起，执行完被调用方法后，再恢复原来的事务。
- **PROPAGATION_MANDATORY** - 若调用方方法存在事务，被调用方法会加入该事务；若调用方方法没有事务，调用被调用方法时会抛出异常。
- **PROPAGATION_NEVER** - 被调用方法以非事务方式执行。若调用方方法存在事务，调用被调用方法时会抛出异常。
- **PROPAGATION_NESTED** - 若调用方方法存在事务，被调用方法会在当前事务中嵌套一个新的事务；若调用方方法没有事务，被调用方法会创建一个新的事务。嵌套事务是外层事务的子事务，有自己的保存点，嵌套事务回滚时，只回滚到保存点，不影响外层事务；外层事务回滚时，嵌套事务也会回滚。

## Spring事物失效的场景

- 异常未被处理或者抛出了非受检异常(RuntimeException的子类) 直接回滚
- 使用this调用方法，会绕过aop代理，调用增强之前的代码逻辑
- 事物嵌套并且传播属性配置不正确
- 多事物源，事物管理没有正确配置
- 跨方法调用，事物内部调用没有@Transcational注解的方法，外层事物可能失效
- 事物标注在非public方法上
- 正确的事物配置，注解@EnableTransactionManagement xml配置文件
- ![截屏2025-03-19 18.32.43](https://typora---------image.oss-cn-beijing.aliyuncs.com/%E6%88%AA%E5%B1%8F2025-03-19%2018.32.43.png)

## Spring事物使用方式

- 编程式 - 通过TransactionTemplate 手动管理事务，提交一个事物任务
- 声明式 - xml - <tx:advice> - 配置事物切面(各级级别，传播方式)  使用aop切面将配置好的事物应用到切点
- 注解声明  -  配置类使用@EnableTranscationManagement  事物方法使用@Transcation

## Spring**循环依赖**

普通三级缓存 失效场景

- 构造器注入的循环依赖
- 原型(ProtoType)的循环依赖 (每个bean都要现场创建)循环依赖双方都是原型就会出问题
- 带有@Async注解的bean @Async注解标注方法异步执行(通过对象代理实现)，会在实例化之后属性注入之前，提前创建代理对象，绕过ObjectFactory创建阶段，被注入的bean只能获取到原始对象，方法无法异步执行

**解决**

- @Lazy注解 创建代理对象填充，真正使用再创建
- 为bean增加EnableAspectJAutoProxy注解，强制获取当前代理对象，避免获得原始对象
- 使用setter注入bean而非构造器



## SpringBean装配

- xml文件定义
- 开启注解扫描+@Component
- @Configuration + @Bean

## Spring 依赖注入方式

- 构造器注入 - 强制
- setter注入 - 获取setter方法注入
- 字段注入 - 反射强制注入
- 接口注入 可以通过@Primary 或者 @Qualifaier - 强制

# 集合

## ConcurrentHashMap

**初始化** - 第一次调用put才会初始化concurrentHashMap

维护一个volatile修饰的状态变量

很多线程争抢初始化 需要循环尝试将这个变量cas为负数 然后在循环的开始 如果发现这个变量被别人修改过了(也就是成负数了)

调用yield函数 尝试让出cpu时间片，然后下一次进入循环如果发现初始化完成就可以直接运行下去了



**put原理**

首先判断node数组是否为空 进入上述的初始化阶段

找到put的目标位置(使用Unsafe的tabAt方法 可以以volatile的形式获取值 这里的node数组被volatile修饰 但是数组里的元素不一定是最新值 也就是从主存中去获取值，防止多线程环境下这个位子已经被别人cas结束了但自己没发现)，如果发现目标为空，也就是自己是第一个元素，会使用cas尝试直接插入数据 如果成功就结束了

如果已经存在元素 需要进行链表的查找修改或者追加，synchronized锁住链表头(此时还是使用tabAt方法去获取) 这里有一步doubleCheck(再次node对象没有发生变化 多线程都运行到这个位置抢锁 一个抢完锁运行结束后可能有扩容操作 刚才别的对象还会去抢锁)  然后是hashMap一样的流程 先去一个个去equals 看看有没有节点可以直接替换 不然就在最后追加一个节点

<u>*以链表头作为锁 锁粒度小*</u>



在扩容时，ConcurrentHashMap支持多线程并发扩容，在扩容过程中同时支持get查数据，若有线程put数据，还会帮助一起扩容，这种无阻塞算法，将并行最大化的设计，堪称一绝



## hashMap冲突解决办法

- 开放寻址 - 线性探测 向后遍历找到空位
- 拉链法 - 链表 红黑树
- 再哈希法 - 准备多个hash函数
- 建立公共溢出区 - 将冲突元素存储在溢出表 寻找元素先从原始hashMap寻找 再从溢出表寻找

## hashMap1.8先插入再扩容的优化

- 1.8扩容引入高低位算法 先插入再扩容使得插入的元素也会使用这个算法 结构完整利用率高
- 老版本 - 先判断used+1/size是否到达负载因子数，如果则先扩容 但是如果这次put仅仅是覆盖了一个元素没有必要进行扩容操作，先put再扩容就可以确定put完成后是否真正有元素数量上的增加
- 由于1.8引入了红黑树，假设有一颗很大的红黑树，先做扩容红黑树节点分成2份，一份完成了🌲化，一份在树化的边缘7，如果此时插入到这个7的位置，又要进行一次树化，树化的过程很消耗性能，如果先插入，后面两波一起树化是否有性能上的提升?

## 红黑树特点

- 跟节点黑色
- 叶子节点黑色(虚拟的指向null)
- 所有叶子节点在同一层
- 红节点不连续(红节点的叶子都是黑色)
- 一个节点到其所有叶子节点的所有路径包含的黑色节点数量相同
- 最长路径不超过最短路径的2倍人



# 消息队列

## **消息高可用**

- 多副本 - kafka为分区建立多replica 副本同步 自动故障转移
- 消息队列分布式部署 - rabbitMQ的镜像集群模式 
- 消息持久化
- 消息发送重试
- 消费失败数据处理 - rabbitMQ 死信交换机
- 幂等性
- 事物

## 消息一致性

- 消息持久化 - kafka记录log日志 rabbitMQ lazyQueue 持久化交换机和队列
- 消息确认机制
- kafka 幂等性 rabbitMQ comfirm模式
- kafka 事物 实现多消息分发topic partition rabbit事物模式完成生产者消息发送

## 消息队列消息积压

- **生产者**流量控制，降级限流
- **消息队列**扩容，设置过期策略 性能优化 负载均衡避免单点瓶颈(根据业务逻辑压缩消息，id一样的去前留后)
- **消费者**简化消息消费逻辑 增加消费者的数量 看看是不是出了bug - 手动提交offset失败



- 事前规划系统容量(选择合适硬件) 部署流量控制机制 优化消费者性能 定期压力测试寻找潜在性能问题
- 事中 当预警出现 
- 事后再次拓展消费者，优化消费逻辑，调整生产者消息发送策略，清理失去时效性的积压消息



事中预警出现，首先手动增加分区和消费者，这样子在生产者生产数据速率不变的情况下， 数据的分布会更加分散，消费者的消费效率也会变高 - 这是对新产生数据的处理

对于已经发生了消息积压的partition，我手动再创建一个topic，设置比原来多几倍的partition，然后记录原来消费者消费的最后offset，并且修改原来消费者的消费逻辑，改为将这些积压消息发送到我新创建的topic 并且附带offset，在新的partition中匹配足够数量的消费者，大幅度提高数据的消费能力

更改消费逻辑的操作比较冒险，建立好完善的回滚机制，应对突发情况

对于rabbitMQ这样子的消息队列，队列存满之后会将最老的数据丢弃，应对这种情况只能在事后（由于我们对交换机队列数据都做了持久化 - lazyQueue）在深夜，生产者的低谷，写一个临时程序，手动将过期或者漏下的积压数据重新加入到队列中去



## kafka吞吐量高的原因

- **分区**并行处理
- **分布式**架构，topic分散在集群中，容错高
- **index**
- 数据存储 **日志**顺序写入，效率高    减少了磁盘的**寻道时间和旋转延迟**
- 利用操作系统的**页缓存**，写入写入缓存，读取先读缓存
- **零拷贝**(数据直接从内核空间到socket缓冲区) DMA技术实现磁盘到内核空间的拷贝 解放cpu降低系统开销
- 批量传输，降低网络开销
- 生产者异步发送，不阻塞等待前一条消息的传输结果
- **轻量级序列化**，减少数据处理开销

## kafka Rebalance带来的问题

消费中断，高延迟，消息队列停止对外提供服务

offset可能错误设置，导致数据重复消费

反复重平衡造成系统可用性下降，大量rebalance造成吞吐量下降



## kafka消息重复消费情况

- 消费者提交offset前故障重启
- 消费者提交offset前发生Rebalance
- 生产者网络波动导致重试
- ack机制导致等待节点落盘超出时间限制，生产者主动重发消息
- 生产者消费者事务提交问题
- 故障重启没有使用leader epoch checkPoint 仅仅使用了LEO+HW

## kafka生产者消费者保证消息幂等性

- 生产者幂等性
- 生产者提交事务启动事务，保证只有一次提交成功
- 消费者建立唯一id
- 消费者基于业务逻辑判断
- 消费者维护好offset的跟新 使用事务

## rabbitMQ的顺序消费

- 一个que一个消费者没有问题
- 为了提高性能，一台交换机准备多个que，确定要业务路由规则
- que多消费者的情况下，维护好顺序ID，消费者发现id不连续了，就阻塞等待

## rabbitMQ 优化思路

**配置优化**

- 高性能场景，或者**临时**存储场景，不使用持久化队列，提高性能
- 使用恰当队列 - 经典队列(存储在内存，磁盘) **流队列**(高版本，类似日志，追加写入，高效，支持多消费者从不同位置消费)
- **预取值** 一个que有多个消费者的情况

**消息路由优化**

- 选择合适**交换机类型** - fanout direct topic
- 保持交换机和队列的**简单绑定，**避免在交换机上绑定不必要的队列
- **消息批量发送**

**生产者消费者**

- 使用**comfirm**模式，异步发送消息，异步等待消息发送执行结果
- 使用**消费者群**并发处理数据
- 追求高吞吐量，尝试把**消息消费确认**由手动改为自动

**硬件优化**

- cpu密集型，提高cpu性能 **多核高频cpu**
- lazy que 直接写数据到磁盘持久化，使用ssd**固态硬盘**提升磁盘IO性能
- 提高**网络带宽**

**集群**

- 普通集群模式
- 镜像集群模式

**监控**

- rabbitMQ自带监控功能组件
- 定期分析rabbitMQ运行日志 连接数，消费者状态



# JVM

## MAT

当系统疑似发生内存泄露问题，我们需要生成堆内存快照 并使用MAT工具分析

对象之间存在引用关系，但是引用关系过于复杂，无法判断出究竟是哪个对象的存在导致的内存泄漏

我们需要**把对象间的引用关系转换为对象的支配关系**，一个对象内部引用了另外一个对象可以说他们之间存在引用关系

支配树上体现的关系就是一个对象如果发生内存泄漏的最直接原因

但是被引用的对象可能还会被其他对象引用，所以说如果发生了内存泄漏，A中引用B，B对象如果内存泄漏，不一定就是A导致的

如果A支配B，那么存在大量的B，发生内存泄漏，就肯定是A导致的，这就是支配的意义

寻找支配的方法，如果一个对象B只被A引用，那么A支配B，但是如果AC同时引用B，寻找AC的共同被引用对象(一个，两个重复，直到唯一)

支配树一定是树状的，其中对象本身占用的空间位浅堆，对象的子树就是深堆，也就是保留集。深堆的大小代表这个对象被回收可以释放的内存空间

MAT根据支配树，从叶子节点向根节点遍历，如果发现某个节点的深堆大小超过堆内存的一定比例，代表可能是内存泄漏的嫌疑对象

## "消除"stw

stw

stop the word

这个应该是对于垃圾回收器而言的

一个垃圾回收算法定义内存回收的逻辑，会分为很多步(标记并清理对象)，而垃圾回收器是执行者，它来决定是否暂停用户线程，是否并发执行线程





- 合理配置堆内存 - 调整堆大小，防止新生代太小，对象创建频繁，频繁gc。调整新生代和老年代的比例
- 复用对象 - 线程池
- 避免大对象和长生命周期对象 减少垃圾回收压力 增加效率
- 减少静态变量集合的使用，占用内存，可分配对象内存降低，gc频繁



工程上尝试减少平衡stw

stw 长到短 

单线程到多线程到Shenandoah和ZGC

stw从不可控到可控

从CMS到G1



AzulGC理论上的 没有stw的垃圾回收器

**C4（Continuously Concurrent Compacting Collector）和GPGC（Generational Pauseless Garbage Collector）**

分代并发 分代压缩

## jvm层面创建一个对象

- 首先加载类的class文件 加载连接(验证准备解析)初始化
- 在堆上分配内存 - 碰撞指针 空闲列表
- 初始化除对象头外的所有内存空间为0值 - 保证**实例对象**可以被直接使用
- 初始化对象头 mark word  class word hash 分代年龄
- 实例代码块
- 构造方法
- 返回引用



创建对象的时候会保证内存分配并发问题

- **CAS+重试**，在某一位置准备分配内存的时候，首先JVM记录该位子的旧值，不断使用cas将内存换为新值，若发现旧值变动了，则会记录目前值，重新做整体的cas
- **TLAB** - Thread Local Allocation Buffer 线程启动的时候，JVM为每个线程在Eden区分配一块TLAB内存区域，线程在创建对象的时候，首先检查自己的TLAB是否有足够的内存，如果有直接分配，不需要同步操作，效率特别高，内存不够用的时候，才会使用cas的操作去分配

## **对象内存布局**

- 对象头- mark word(hash 分代年龄 锁状态 偏向线程id) + class word
- 实例数据
- 对其填充 要求对象大小为8字节的整数倍

## 对象的访问定位

对象变量和实际地址的绑定过程

- 句柄 - 局部变量表中的变量指向堆中句柄池中某个句柄对象，句柄对象里有两个指针分别指向对象实例数据和方法区中的InstanceClass对象(对象发生变更，变量指向本身不用发生变化，只需要修改句柄对象)
- 直接指针 - 变量直接指向对象地址(只需要一次指针定位，效率高)

## GC Roots

- 虚拟机栈和本地方法栈中引用的对象(局部变量表)
- 方法区中静态属性引用的对象和常量引用的对象
- 同步锁持有的对象

## 手动实现可达性分析算法

我们使用三色标记法(ZGC,CMS,G1并发回收原理)

初始标记，并发标记，最终标记

三种颜色  白色 - 还未被访问过  灰色 - 访问过，但是其子对象还没被访问  黑色 - 访问完毕

所有对象首先初始化为白色的，将GCROOT对象可以直接关联的对象标记为灰色，加入一个队列，不断从队列中取出元素，首先标记为黑色的，并将其直接可达的白色对象加入队列，并上灰色，直到只剩白色对象，全部clear



**并发标记会有两种问题**

- 浮动垃圾，并发过程中，一个对象由可达变为了不可达，这个问题不大，在下一次GC是会被回收
- 对象消失问题 - 一个灰色对象对一个白色对象的引用消失，但是这个白色对象被黑色对象引用了，但是黑色对象无法将白色对象加入队列了，导致这个白色对象被回收，但是引用仍然存在

**解决方案**

- 增量跟新 - Incremental Update

**CMS使用** 当黑色对象插入对白色对象的引用的时候，将黑色对象重新标记为灰色，重新扫描其引用对象

- 原始快照 - Snapshot At The Beginning

**ZGC G1使用** 当灰色对象删除白色对象的引用的时候，将白色对象记录下来，后续强行标记为存活



增量更新更精准，但是需要重复扫描，增加stw时间

STAB snapshot是什么意思，它假设GC开始的时候，所有的对象引用关系都存在，即使后面被删除，也将起标记为存在，所以灰色对象删除了白色对象的引用，将白色对象标记为删除，防止白色对象被黑色对象引用这一情况。这是一种保守策略，可能过度标记，减少扫描次数

## 判断类可以被回收

- 类的所有实例被回收
- 类的类加载器被回收
- 类对应的java.lang.Class对象没有被引用

## HotSpot 为什么要分为新生代和老年代？

大部分对象存活时间短，小部分对象存活时间长，让不同生命周期的对象处于不同的区域可以提高垃圾回收的效率

- 新生代存放生命周期短的对象，发生垃圾回收的频率高，使用复制算法，由于大量对象会被回收，复制的成本低
- 老年代的对象由新生代晋升过来，对象稳定，即使使用标记整理这样子的低效率算法也可以接受
- 两个区域基本都不会产生内存碎片

## jvm参数

- -Xmx -Xms 最大堆内存 初始堆内存
- -Xss 虚拟机栈大小
- -XX:MaxMetaspaceSize 元空间最大内存
- -XX:MetaspaceSize 元空间GC阈值
- -Xmn 年轻代大小 默认整个堆1/3(指定内存大小，初始和最大值相同)
- -XX:NewSize  -XX:MaxNewSize 新生代内存初始和最大大小
- -XX:NewRatio
- -XX:SurvivorRatio 伊甸园区和幸存者区的比例
- -XX:MaxtenuringThreshold 最大年龄晋升阈值
- -XX:+HeapDumpOnOutOfMemoryError 发生outOfMemoryError错误生成堆内存快照
- -XX:+PrintGCDetails 打印GC日志

```
-XX:+UseSerialGC
-XX:+UseParallelGC
-XX:+UseConcMarkSweepGC
-XX:+UseG1GC
```



## 导致CPU 100%的情况

- 无限循环 无锁cas cpu自旋
- 大规模死锁，不断互相争抢锁
- 大量计算密集任务
- 线程池配置（线程数量过多，上下文切换榨干了cpu）(newCachedThreadPool)
- 频繁垃圾回收

## CPU 100%排查

- 使用top 找到cpu占用最高的java进程pid
- 使用top -Hp + pid 找到cpu占有率最高的java线程
- 使用jdk中的工具jstack + 进程pid  获取到目标进程的线程快照（进程中的所有线程）
- 根据线程id在上一步的线程快照中找到记录位置，可以找到消耗cpu的代码行



- 启动arthas，attach 使用top找到的cpu爆满的进程id
- 执行thread 获取到这个进程下的线程信息界面
- thread + 线程id 获取到他的线程快照，线程执行情况

## 内存泄漏检测小结

**内存监控工具**

- top命令  -  整体内存使用情况，无具体部分组成
- visualVm Oracle jdk有 open jdk没有
- arthas
- prometheus(数据采集) + grafana(数据可视化)



导出堆内存快照，MAT分析内存泄漏原因

- jvm参数HeapDumpOnOutOfMemoryError
- jmap命令直接导出
- jhat 建立http/html服务器，在浏览器上分析堆内存快照
- arthas的heapDump命令导出
- visualVm选中进程右键可以导出



## GC调优

目标 - 吞吐量，延迟，内存使用量



- jstat -gc + 进程id，分析不同内存分区gc的各自情况
- visualVM的插件visual Tool监控垃圾回收时间变化趋势
- prometheus + grafana
- jvm参数 - PrintGCDetails 手动查看gc日志
- 通过一些gc工具分析gc日志

日志可视化通常是 堆内存的使用和时间的关系，堆内存的快速下降代表进行了垃圾回收

正常情况 - 堆内存随着时间大起大落(对象累计 - 对象回收)

缓存多 - 对象起落幅度接近，但是下降最低点比较高，因为有很多缓存对象

内存泄漏 - 对象每次垃圾回收效果越来越不明显，最低值越来越高，直到最后一个gc回收不了一个对象

图上红点 - 持续fullGC cpu爆满 - 请求激增

元空间内存不足 - 图上堆内存占用不大，但是持续发生fullGc



## 接口响应时间优化

- arthas -trace and watch 命令 展示方法调用路径和各方法执行时间
- arthas火焰图纵向呈现方法执行时间，颜色的不同容易看出哪一方法执行耗时很长(比如可以根据结果做优化，jdk的split分割要使用正则表达式，很多情况可以应对复杂场景，但是效率不高)

## **接口响应时间慢排查**

首先判断是所有接口都慢(服务器，数据库，网络问题)

还是单独某个接口慢(业务逻辑，sql，索引问题) 

- 网络排查 - ping 检查服务器的连通性和往返时间，查看延迟和丢包率
- 使用top命令查看cpu和内存使用情况，docker status查看docker部署项目的执行情况，判断是否有死锁啊无限循环
- 查看mysql Max-Connection 是否连接池资源耗尽
- 具体业务代码，优化慢sql，替换jdk核心慢代码
- 调整jvm堆内存，避免频繁gc
- 使用g1垃圾回收器，监控gc日志
- 设置缓存
- 对于第三方接口调用，完善好超时等待中止和异步调用 熔断与降级逻辑

## 死锁检测

- jstack + 进程id 获取进程的所有线程快照 查找deadlock发现死锁位置
- 使用VisualVm和Jconsole 可以检测死锁
- 使用在线工具可以自动分析 thread dump 检测是否有死锁存在



## OOM和JVM退出的关系

JVM退出的条件 - 所有非守护线程执行结束

OOM本质是一个异常，会导致其所在线程提前结束，但是如果此时还存在其他非守护线程正在工作，JVM也不会结束



case1

所有的非守护线程都要消耗JVM内存资源，一个线程出发了OOM，会导致连锁的OOM，JVM退出

case2

再严重一点，不仅JVM的内存被消耗完了，整个操作系统的内存都消耗完了，那么会发生OOM Killer，JVM进程被迫结束，导致JVM退出

## 垃圾回收器总结

serial + serialOld 是单线程stw垃圾回收，ParNew / parallel GC 都是在stw的基础上使用多线程进行优化，但是一个注重暂停时间，一个注重吞吐量，他们是做回收多线程的优化，而CMS G1是在对垃圾回收算法的改进，将普通的标记stw阶段，优化为初始，并发(有应对策略，直接，satb)，重新标记，并优化并发回收



**Serial + Serial Old**

新生代 复制算法  老年代 标记整理算法  垃圾回收过程中持续stw 比较简单

**ParNew + CMS**

新生代 复制算法 老年代 标记清楚 serial的多线程优化版本

CMS - concurrent mark sweep

初始标记，并发标记，重新标记(stw，修正前一并发阶段用户造成的所有标记偏差)，并发清理

有浮动垃圾 内存碎片化

**promotion failed** - minor gc的时候对象无法放入survivor区域，也无法直接放入老年区 - stw

**concurrent mode failed** - CMS GC过程中 有对象要放入老年代，空间不足 - stw

**Parallel Scavenge + Parallel Old**

新生代 复制算法 老年代 标记整理

也是多线程收集，关注吞吐量，高效率利用cpu(运行用户代码时间和cpu消耗总时间比值)

**G1**

- 取消年轻代和老年代的物理划分，但还是属于分代回收

- 可以充分利用多核cpu进行真正意义上的并行清理
- 以复制算法实现了整理
- 将内存分为region 一方面让stw可控，一方面可以根据regin存活度高效回收垃圾

初始标记，并发标记，重新标记(只看漏标)，筛选回收(选取存活度最低的regin，只需要把少量对象复制到其他区域就可以完成这个region的垃圾回收)

## class文件内容

- 一般信息(版本号，常量池计数，访问标识，接口计数，字段计数，方法技术，属性技术) - 元信息
- 常量池
- 接口
- 字段
- 方法
- 属性

## 类加载过程

**加载**

- 通过全限定名获取类的二进制流(多种渠道，磁盘 网络等)
- 加载到内存，在方法区中生成InstanceClass对象
- 在堆区中生成java.lang.class对象

**验证**

- 验证格式，元数据，字节码，符号引用正确性(类要访问的其他类方法是否存在)

**准备**

- 为非final静态变量赋初值，final静态变量直接赋值

**解析**

- 符号引用替换为直接饮用（类编译阶段某个类无法确定引用类的实际地址，用一个符号替代，后续更换为真正的地址，甚至到运行阶段才会确定(帧数据中有动态链接，运行时根据实际情况将符号引用解析成具体的内存地址)）

**初始化**

执行静态代码块的内容并为静态变量赋值



**以下几种方式会导致类的初始化**

- 访问一个类的静态变量或者静态方法，但是变量为final修饰且等号右边为常量不会触发初始化
- 调用Class.forName(String className) 底层有方法重载 默认会使类初始化 也可以自己加参数false让他不初始化
- new 一个类的对象
- 执行Main方法的当先类
- 作为一个类的父类，子类被初始化的时候被触发

**类Class文件gc条件**

- 类的所有实例对象和子类对象被回收

- 类加载器被回收

- java.lang.class对象没有引用

  

## Java代码的编译底层原理

两个阶段 - .java - .class - 机器码文件



首先使用javac把源文件编译成字节码文件

- 将源代码转换成token序列(按顺序去读取每一个字符，组成一个个序列，比如把访问修饰符，关键字，标识符 一个个抽象出来到序列中)
- 根据token序列构建抽象语法树 - AST - 每个节点是一个语法逻辑结构(类，方法)
- 根据语法树检查变量类型，程序逻辑
- 将AST转成字节码指令(魔数，版本号，常量池，字面量)



JVM逐行读取字节码并执行，引入JIT优化(热点代码，方法内链，逃逸分析，栈上分配) AOT(ahead of time 提前把字节码编译成机器码)



## FULL GC时机

- 老年代空间不足，新生代对象无法正常晋升加入 或者promotion failed(survivor区无法放下对象，对象无视年龄直接从eden区到老年代)
- 方法区内存满(永久代满了fullgc，元空间有垃圾回收阈值和整体阈值)
- CMS -  concurrent mode failure - cms垃圾回收是多线程的，cms回收过程中，有对象要加入老年代空间不足，会发生fullGC
- 老年代剩余空间和新生代所有对象内存比较(前置操作，jdk6以前)，然后通过判断担保机制(jdk6后自动开启)
- 调用Full GC 不一定百分百执行

## 对象分配原则

- 优先分配eden，eden内存到达阈值，触发minor gc
- 大对象直接进入老年代，避免在新生代中来回复制
- 对象晋升
- 动态判断年龄，如果survivor区中相同年龄对象总和大于Survivor一半，大于等于该年龄的对象直接进去老年代
- 以上是对象在堆中分配，如果经过逃逸分析，可以栈上分配，标量替换(对象变为基本数据类型) - 不用垃圾回收，减少内存

## 什么是OopMap和安全点

**OopMap介绍**

- OopMap是JVM用于记录对象引用位置的数据结构，帮助GC快速定位内存中哪些位置有对象引用，避免全量扫描内存

- OopMap帮助GC快速定位根对象，高效完成存活对象标记

**工作流程**

- JIT编译的时候，在**特定位置**(方法入口，循环结束位置)生成OopMap记录此时栈帧(局部变量表)存储了哪些对象的引用，直接标记位置
- 解释执行的代码，JVM在执行过程中动态维护引用位置信息，也就是编译时无法确定的对象，gc触发，对栈帧扫描



**安全点概念**

程序执行过程中可以安全暂停线程并执行GC的特定位置，GC需要stw，而线程只能在安全点处被暂停

**安全点的意义**

- 若允许线程在任意位置被暂停，有可能此时线程处于中间状态(正在修改指针)GC无法准确获取对象引用关系，导致引用错乱(区别于重新标记的过程)
- 安全点的暂停，对象引用稳定GC访问安全

**安全点位置**

在特定位置设立安全点

- 方法返回处
- 循环结束位置
- 异常抛出的位置
- JIT编译代码块边界



OopMap仅在安全点生成(记录所有可达对象)

## 栈上存储

数据在栈上的存储，对于引用类型存储引用

对于基本数据类型

存放在**栈帧的局部变量表**中



局部变量表分为一个一个的**slot槽**

32位虚拟机槽大小32位，4字节，64位8字节

Java中long和double是8字节的，为了两者统一，long，double**统一使用两个槽存储**





无论是long，double的**存储冗余**，还是boolean，byte这种小于四个字节的存储冗余是空间浪费，但是运行效率提高，他们可以使用统一的规则去处理，Java不需要在局部变量表中去存储变量类型，只根据slot槽对数据进行处理，用**空间换时间**



boolean在栈上当作int存储，0/1





堆中数据和栈中数据的加载转化

堆中数据的存储内存要小于等于栈中

堆到栈，需要补齐高位，设计符号位

栈到堆，截断高位





## 对象存储

markword+classword+(长度，数组对象)+对象数据+内存填充



markword



- 空白区域+hash+cms状态+分代年龄+偏向锁状态+锁状态 - 正常

- 偏向🔒ID，偏向所时间戳 - cms状态，分代年龄，偏向🔒，锁状态 - 偏向锁

- 指向锁记录，lock recode指针 + 锁状态 - 轻量级锁

- 指向monitor指针 + 锁状态 - 重量级锁

- 空 + 锁状态 - 垃圾回收



64位不开启指针压缩，会把cms状态删除位空





## 方法调用

本质 - 通过字节码指令的执行，在栈上创建栈帧，执行方法的字节码指令



**静态绑定**

编译期间，方法字节码指令位一个符号引用，引用到常量池中的方法定义 - 类名+方法名+返回值+参数

方法第一次调用，将符号引用替换为内存地址的直接引用

使用静态，私有，final方法，因为其无法被继承重写



**动态绑定**

可能被子类重写的方法

在instanceClass中维护需方法表，记录各个方法的地址，子类虚方法表记录父类虚方法表中的所有内容，子类重写父类方法，对虚方法表中的内容进行替换







**JIT**

HotSpot虚拟机是最常用的虚拟机

它的作用是翻译字节码为机器码，有两种机制 - 

解释器 - 直接解释字节码，效率低适合一次性的代码

JIT编译器 - **分层编译，方法内连，逃逸分析**



JIT使用C1 C2编译器完成分层编译

- C1编译效率高，但是代码优化效果不如C2 - 适合执行时间短的代码

- C2 - 编译效率低，但是代码优化效果好 - 适合长期执行的代码



分层编译 - 根据**优化级别**分为**5个等级**

- 解释器

- C1 - 仅仅优化

- C1 - 优化 + 记录部分信息

- C1 - 优化 + 记录完整信息

- C2 - 完整优化

信息指的是**方法执行次数 循环执行次数，分支执行次数**(因为要做代码编译保存优化)



C1 C2由彼此独立线程进行处理，内部保存队列，队列中存放要编译的任务

任务是**方法或者循环级别的**



C1 C2**配合过程**

- C1编译执行，记录信息(上述)，达到一定阈值，由C2对这个代码进行深层次优化

- 字节码少的代码块，收集信息后，JVM判断C1，C2性能差不多，C1直接优化

- C1线程在忙，C2直接优化

- C2忙碌的时候，C1分层次去做编译和信息收集，等到C2不忙碌了，让C2执行优化



JIT优化手段

**方法内联** - 方法字节码直接粘到调用方



**逃逸分析** - 锁消除 - 标量替换(对象栈上分配)



## 垃圾回收器原理

**G1垃圾回收器**

卡表，rememberSet记忆集，写屏障 三色标记



**ZGC** 

读屏障 着色指针



**Shenandoah GC** 

与G1相似

没有着色指针，通过修改对象头的设计来完成并发转移过程的实现























​	
